{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4",
      "provenance": [],
      "authorship_tag": "ABX9TyN1A9vSOUAS0C2CjUieDJt6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiao-lyc/HW4/blob/master/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEjLtegyXuLh",
        "outputId": "52f297f3-2ad4-46c6-cfa2-701896087ea9"
      },
      "source": [
        "!pip3 install opencc-python-reimplemented"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencc-python-reimplemented in /usr/local/lib/python3.7/dist-packages (0.1.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfV53vR4X5rO",
        "outputId": "9e24323a-c484-4ac0-9f35-1f65849cbabe"
      },
      "source": [
        "!pip3 install gensim"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcWFvkuidqzn",
        "outputId": "ed2d8aba-8c7f-4db6-e62c-baa2f877bfa6"
      },
      "source": [
        "!pip install word2vec"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting word2vec\n",
            "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 505 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.19.5)\n",
            "Building wheels for collected packages: word2vec\n",
            "  Building wheel for word2vec (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2vec: filename=word2vec-0.11.1-py2.py3-none-any.whl size=156423 sha256=4d5810e8f70092b12825d93d922ed5a8ba04127df5c574dec0359062189d4f20\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/c0/d4/29d797817e268124a32b6cf8beb8b8fe87b86f099d5a049e61\n",
            "Successfully built word2vec\n",
            "Installing collected packages: word2vec\n",
            "Successfully installed word2vec-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsyHbNZPX9fP",
        "outputId": "d0d289f5-b12d-4979-ea20-022e86d86b33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLJcqDmaYMFc",
        "outputId": "916defe5-e6b6-4832-a1fc-2640d8603ea2"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 把列出資料夾的程式碼寫成一個函式\n",
        "filePath = []\n",
        "def show_folder_content(folder_path):\n",
        "    folder_content = os.listdir(folder_path)\n",
        "    for item in folder_content:\n",
        "        if os.path.isdir(folder_path + '/' + item):\n",
        "            # 呼叫自己處理這個子資料夾\n",
        "            show_folder_content(folder_path + '/' + item)\n",
        "        elif os.path.isfile(folder_path + '/' + item):\n",
        "            filePath.append(folder_path + '/' + item)\n",
        "        else:\n",
        "            print('無法辨識：' + item)\n",
        "\n",
        "\n",
        "# 顯示指定資料夾的內容\n",
        "target_folder = '/content/drive/My Drive/wiki_zh'\n",
        "show_folder_content(target_folder)\n",
        "print(\"Finish\", len(filePath))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish 1247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "JfapWDC0be9N",
        "outputId": "e1f5b6ad-de70-459c-9e3a-fcaa63f9ffb1"
      },
      "source": [
        "# coding=utf-8\n",
        "from opencc import OpenCC\n",
        "import jieba \n",
        "import json\n",
        "import re\n",
        "\n",
        "dictionaryPath = '/content/drive/My Drive/wiki_zh/Model/dict.txt.big'\n",
        "jieba.set_dictionary(dictionaryPath) ##加入繁體中文\n",
        "\n",
        "# Initial\n",
        "cc = OpenCC('s2t')\n",
        "\n",
        "# 讀取停用詞\n",
        "def stopwordslist(filepath):  \n",
        "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]  \n",
        "    return stopwords \n",
        "\n",
        "def LoadToSeg(filepath, fW):\n",
        "    with open(filepath, 'r') as obj:\n",
        "        for line in obj.readlines():\n",
        "            dic = json.loads(line)\n",
        "            temp_text = re.findall('[\\u4e00-\\u9fa5]', cc.convert(dic['text']))\n",
        "            text = ''.join(temp_text)\n",
        "            tags = jieba.lcut(text, cut_all=False)\n",
        "            ThisLine = ''\n",
        "            for tag in tags:\n",
        "                if tag not in stopwords:  \n",
        "                    if tag != '\\t' and tag != '\\n' and tag != '' and len(tag) > 1:  \n",
        "                        ThisLine += tag  \n",
        "                        ThisLine += \" \"   #再次組合成【帶空格】的串\n",
        "            fW.write((ThisLine+\"\\n\").encode('utf-8'))\n",
        "stopwords = stopwordslist('/content/drive/My Drive/wiki_zh/Model/StopWords.txt')  # 這裏加載停用詞的路徑 \n",
        "fileSegWordDonePath ='/content/drive/My Drive/wiki_zh/Model/corpusSegDone.txt'\n",
        "with open(fileSegWordDonePath,'wb') as fW:\n",
        "    fW.truncate(0)\n",
        "    index = 0\n",
        "    for path in filePath:\n",
        "        LoadToSeg(path, fW)\n",
        "        index += 1\n",
        "        if index % 100 == 0:\n",
        "            print(index)\n",
        "\n",
        "print(\"Finish\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PermissionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e0c67898ad17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwordslist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/wiki_zh/DriveUploader/StopWords.txt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 這裏加載停用詞的路徑\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mfileSegWordDonePath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/My Drive/wiki_zh/DriveUploader/corpusSegDone.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileSegWordDonePath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mfW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: '/content/drive/My Drive/wiki_zh/DriveUploader/corpusSegDone.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oeBKzGjbfXR"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "# jieba分詞轉word2vec向量\n",
        "fileSegWordDonePath ='/content/drive/My Drive/wiki_zh/Model/corpusSegDone.txt'\n",
        "fileSegWordDonePath2 ='/content/drive/My Drive/wiki_zh/Model/corpusSegDone.model'\n",
        "\n",
        "# Settings\n",
        "sentences = word2vec.LineSentence(fileSegWordDonePath)\n",
        "model = word2vec.Word2Vec(sentences, seed = 666, sg = 0, window = 10, min_count = 1, workers = 8)\n",
        "model.save(fileSegWordDonePath2)\n",
        "print(\"Finish\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9bDRVBzdFrJ"
      },
      "source": [
        "# -*- coding: utf-8 -*-# -*- coding: utf-8 -*-\n",
        "import sys\n",
        "from gensim.models import word2vec \n",
        "from gensim import models\n",
        "\n",
        "def main():   \n",
        "    a = input(\"input:\") \n",
        "    fileSegWordDonePath2 = '/content/drive/My Drive/wiki_zh/Model/corpusSegDone.model'\n",
        "    model = models.Word2Vec.load(fileSegWordDonePath2)\n",
        "    try:\n",
        "        res = model.most_similar(a, topn=20)\n",
        "        for item in res: \n",
        "            print(str(item[0]) + ':' + str(item[1]))\n",
        "    except KeyError:\n",
        "        print(a + \" is not in the vocabulary\")\n",
        "\n",
        "if __name__=='__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}